{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydicom'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-083864bc84d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpydicom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pydicom'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import model_from_json, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet import ResNet50 \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from skimage.transform import rescale, resize, downscale_local_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_model():\n",
    "    \n",
    "    model = VGG16(include_top=False, weights='imagenet', input_shape = (512, 512, 3))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_my_model():\n",
    "    \n",
    "    # my_model = Sequential()\n",
    "    # ....add your pre-trained model, and then whatever additional layers you think you might\n",
    "    # want for fine-tuning (Flatteen, Dense, Dropout, etc.)\n",
    "    \n",
    "    # if you want to compile your model within this function, consider which layers of your pre-trained model, \n",
    "    # you want to freeze before you compile \n",
    "    \n",
    "    # also make sure you set your optimizer, loss function, and metrics to monitor\n",
    "    \n",
    "    vgg_model = load_pretrained_model()\n",
    "    \n",
    "    for layer in vgg_model.layers[:17]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    my_model = Sequential()\n",
    "    \n",
    "    my_model.add(vgg_model)\n",
    "    \n",
    "    my_model.add(GlobalAveragePooling2D())\n",
    "    \n",
    "    my_model.add(Dense(256, activation='relu'))\n",
    "    \n",
    "    my_model.add(BatchNormalization())\n",
    "    \n",
    "    my_model.add(Dropout(0.4))\n",
    "    \n",
    "    my_model.add(Dense(64, activation='relu'))\n",
    "    \n",
    "    my_model.add(BatchNormalization())\n",
    "    \n",
    "    my_model.add(Dropout(0.3))\n",
    "    \n",
    "    my_model.add(Dense(32, activation='relu'))\n",
    "    \n",
    "    my_model.add(BatchNormalization())\n",
    "    \n",
    "    my_model.add(Dropout(0.3))\n",
    "    \n",
    "    my_model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function reads in a .dcm file, checks the important fields for our device, and returns a numpy array\n",
    "# of just the imaging data\n",
    "def check_dicom(filename): \n",
    "    \n",
    "    print('Load file {} ...'.format(filename))\n",
    "    ds = pydicom.dcmread(filename)   \n",
    "    \n",
    "    if(ds.Modality == 'DX' and ds.PatientPosition in ['PA', 'AP'] and (ds.BodyPartExamined == 'CHEST')):\n",
    "        img = ds.pixel_array\n",
    "        return img\n",
    "    \n",
    "    print('Invalid data...')\n",
    "    return None\n",
    "    \n",
    "# This function takes the numpy array output by check_dicom and \n",
    "# runs the appropriate pre-processing needed for our model input\n",
    "def preprocess_image(img, img_size): \n",
    "    \n",
    "    img = resize(img, (img_size[1], img_size[2]))\n",
    "    \n",
    "    proc_img = (img - img.mean()) / img.std()\n",
    "    \n",
    "    return np.resize(proc_img, img_size)\n",
    "\n",
    "# This function loads in our trained model w/ weights and compiles it \n",
    "def load_model(model_path):\n",
    "    \n",
    "    my_model = build_my_model()\n",
    "    my_model.load_weights(model_path)\n",
    "    \n",
    "    return my_model\n",
    "\n",
    "# This function uses our device's threshold parameters to predict whether or not\n",
    "# the image shows the presence of pneumonia using our trained model\n",
    "def predict_image(model, img, thresh): \n",
    "    \n",
    "    prediction = model(img)\n",
    "    \n",
    "    if(prediction > thresh):\n",
    "        prediction = 'Pneumonia'\n",
    "    else:\n",
    "        prediction = \"No Pneumonia\"\n",
    "        \n",
    "    return prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dicoms = ['test1.dcm','test2.dcm','test3.dcm','test4.dcm','test5.dcm','test6.dcm']\n",
    "\n",
    "model_path = r'xray_class_my_model.h5'\n",
    "\n",
    "IMG_SIZE=(1,512,512,3) # This might be different if you did not use vgg16\n",
    "\n",
    "my_model = load_model(model_path)\n",
    "\n",
    "thresh = 0.25\n",
    "\n",
    "# # use the .dcm files to test your prediction\n",
    "for i in test_dicoms:\n",
    "    \n",
    "    img = check_dicom(i)\n",
    "    \n",
    "    if img is None:\n",
    "        continue\n",
    "    \n",
    "    img_proc = preprocess_image(img, IMG_SIZE)\n",
    "\n",
    "    pred = predict_image(my_model,img_proc,thresh)\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
